{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Assembly Data Science Immersive, by Elliot Cohen\n",
    "## Part 1\n",
    "### Python Coding and Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import ttest_ind\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q: Load in the data file and header file provided\n",
    "header_url = 'https://gist.githubusercontent.com/jeff-boykin/b5c536467c30d66ab97cd1f5c9a3497d/raw/5233c792af49c9b78f20c35d5cd729e1307a7df7/field_names.txt'\n",
    "header_list = pd.read_csv(header_url, header=None, squeeze=True).tolist();\n",
    "\n",
    "data_url = 'https://gist.githubusercontent.com/jeff-boykin/b5c536467c30d66ab97cd1f5c9a3497d/raw/5233c792af49c9b78f20c35d5cd729e1307a7df7/breast-cancer.csv'\n",
    "data = pd.read_csv(data_url, header=None, names=header_list, index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_sd_error</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_sd_error</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_sd_error</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_sd_error</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_sd_error</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_sd_error</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569</td>\n",
       "      <td>569.00</td>\n",
       "      <td>569.00</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.00</td>\n",
       "      <td>569.00</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>569.0000</td>\n",
       "      <td>569.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>456.00</td>\n",
       "      <td>479.00</td>\n",
       "      <td>522.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>474.0000</td>\n",
       "      <td>537.0000</td>\n",
       "      <td>537.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>432.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>457.00</td>\n",
       "      <td>511.00</td>\n",
       "      <td>514.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>411.0000</td>\n",
       "      <td>529.0000</td>\n",
       "      <td>539.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>535.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B</td>\n",
       "      <td>12.34</td>\n",
       "      <td>18.22</td>\n",
       "      <td>134.7</td>\n",
       "      <td>512.2</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>27.26</td>\n",
       "      <td>101.7</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.07427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>357</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis  radius_mean  radius_sd_error  radius_worst  texture_mean  \\\n",
       "count        569       569.00           569.00         569.0         569.0   \n",
       "unique         2       456.00           479.00         522.0         539.0   \n",
       "top            B        12.34            18.22         134.7         512.2   \n",
       "freq         357         4.00             3.00           3.0           3.0   \n",
       "\n",
       "        texture_sd_error  texture_worst  perimeter_mean  perimeter_sd_error  \\\n",
       "count           569.0000       569.0000           569.0               569.0   \n",
       "unique          474.0000       537.0000           537.0               542.0   \n",
       "top               0.1007         0.1147             0.0                 0.0   \n",
       "freq              5.0000         3.0000            13.0                13.0   \n",
       "\n",
       "        perimeter_worst           ...             concavity_worst  \\\n",
       "count          569.0000           ...                      569.00   \n",
       "unique         432.0000           ...                      457.00   \n",
       "top              0.1714           ...                       12.36   \n",
       "freq             4.0000           ...                        5.00   \n",
       "\n",
       "        concave_points_mean  concave_points_sd_error  concave_points_worst  \\\n",
       "count                569.00                    569.0                 569.0   \n",
       "unique               511.00                    514.0                 544.0   \n",
       "top                   27.26                    101.7                 826.4   \n",
       "freq                   3.00                      3.0                   2.0   \n",
       "\n",
       "        symmetry_mean  symmetry_sd_error  symmetry_worst  \\\n",
       "count        569.0000           569.0000           569.0   \n",
       "unique       411.0000           529.0000           539.0   \n",
       "top            0.1216             0.1486             0.0   \n",
       "freq           4.0000             3.0000            13.0   \n",
       "\n",
       "        fractal_dimension_mean  fractal_dimension_sd_error  \\\n",
       "count                    569.0                    569.0000   \n",
       "unique                   492.0                    500.0000   \n",
       "top                        0.0                      0.2383   \n",
       "freq                      13.0                      3.0000   \n",
       "\n",
       "        fractal_dimension_worst  \n",
       "count                 569.00000  \n",
       "unique                535.00000  \n",
       "top                     0.07427  \n",
       "freq                    3.00000  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q: Comment on any steps you might take to evaluate or transform the dataset.\n",
    "# A: Converting the dataframe to pandas built-in type Categorical can be helpful for summary statistics.\n",
    "#    It is also helpful when working with large datasets with repeated values, \n",
    "#    although that is not required here due to the relatively small sample size of our data.\n",
    "data.apply(pd.Categorical).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">smoothness_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">smoothness_sd_error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">smoothness_worst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">compactness_mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">compactness_sd_error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">compactness_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.000321</td>\n",
       "      <td>1.8510</td>\n",
       "      <td>21.135148</td>\n",
       "      <td>19.630</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.021438</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4.323929</td>\n",
       "      <td>3.6795</td>\n",
       "      <td>72.672406</td>\n",
       "      <td>58.455</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.032281</td>\n",
       "      <td>0.02859</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.014205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          smoothness_mean         smoothness_sd_error          \\\n",
       "                     mean  median                mean  median   \n",
       "diagnosis                                                       \n",
       "B                2.000321  1.8510           21.135148  19.630   \n",
       "M                4.323929  3.6795           72.672406  58.455   \n",
       "\n",
       "          smoothness_worst           compactness_mean           \\\n",
       "                      mean    median             mean   median   \n",
       "diagnosis                                                        \n",
       "B                 0.007196  0.006530         0.021438  0.01631   \n",
       "M                 0.006780  0.006209         0.032281  0.02859   \n",
       "\n",
       "          compactness_sd_error           compactness_worst            \n",
       "                          mean    median              mean    median  \n",
       "diagnosis                                                             \n",
       "B                     0.025997  0.018400          0.009858  0.009061  \n",
       "M                     0.041824  0.037125          0.015060  0.014205  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q: Compute the mean and median smoothness and compactness for benign and malignant tumors\n",
    "data.filter(regex='smoothness|compactness|diagnosis').groupby('diagnosis').agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothness: t statitic = 15.934158 p value = 0.000000000\n",
      "compactness: t statitic = 7.297077 p value = 0.000000000\n"
     ]
    }
   ],
   "source": [
    "# Q: Do the groups differ? Explain how you would identify this.\n",
    "# A: Perform a T-test on the means of two independent samples. \n",
    "#    This is a univariate test, and can be done for each predictor, as needed.\n",
    "grouped = data.groupby('diagnosis')\n",
    "malignant = data.loc[grouped.groups['M']]\n",
    "benign = data.loc[grouped.groups['B']]\n",
    "\n",
    "t, p = ttest_ind(malignant['smoothness_mean'], benign['smoothness_mean']) \n",
    "print('{}: t statitic = {:.6f} p value = {:.9f}'.format('smoothness', t, p))\n",
    "\n",
    "t, p = ttest_ind(malignant['compactness_mean'], benign['compactness_mean'])\n",
    "print('{}: t statitic = {:.6f} p value = {:.9f}'.format('compactness', t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the cancer data by diagnosis, and summarizing by smoothness and compactness features, we see a discernable difference in measures of central tendancy (e.g. mean and median). To determine if this difference is statistically significant, we conduct a two-sided T-test with a null hypothesis that the two independent samples are identically distributed.\n",
    "\n",
    "Results indicate that we can __reject the null hypothesis__ that mean cell nuclei smoothness for benign and malignant tupors are the same, based on a p_value approaching zero. Similarly for compactness, we can reject the null hypthoses that benign and malignant cell nuclei compactness are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original smoothness for benign cells: 2.000321\n",
      "resampled smoothness for benign cells: 2.000151\n"
     ]
    }
   ],
   "source": [
    "# Q: Write a function to generate bootstrap samples of the data.\n",
    "def create_bootstrap_samples_from_dataframe(dataframe, n_samples=1000):\n",
    "    assert isinstance(dataframe, pd.core.frame.DataFrame), 'input data must be a pandas dataframe'\n",
    "    return dataframe.sample(n=n_samples, replace=True)\n",
    "\n",
    "# A: Example usage\n",
    "bootstrap_data = create_bootstrap_samples_from_dataframe(data, n_samples=10000)\n",
    "print('original smoothness for benign cells: {:.6f}'.format(data[data['diagnosis']=='B']['smoothness_mean'].mean()))\n",
    "print('resampled smoothness for benign cells: {:.6f}'.format(bootstrap_data[bootstrap_data['diagnosis']=='B']['smoothness_mean'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis\n",
    "Q: Identify 2-3 variables that are predictive of a malignant tumor. Display the relationship visually and write 1-2 sentences explaining the relationship.\n",
    "\n",
    "A: To identify the most important predictive features, I will use one of sklearn's built-in feature selection methods. They are powerful and fast -- ideal for exploratory analysis. We can always come back to tune hyperparameters and thresholds later, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first divide data into predictors (X) and predictand (y), and subdivide into test/train sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y = data['diagnosis'].replace({'M': True, 'B': False}) # convert to binary outcome\n",
    "X = data.iloc[:, data.columns != 'diagnosis']\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that scaled predictors are mean zero and standard deviation 1\n",
    "tolerance = 1*10**-5\n",
    "assert all(abs(X_scaled.mean(axis=0) - 0) <= tolerance) # verify that scaled mean ~=0\n",
    "assert all(abs(X_scaled.std(axis=0) - 1) <= tolerance) # verify that scaled std ~=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 predictors: ['concavity_worst' 'concave_points_sd_error' 'fractal_dimension_mean']\n"
     ]
    }
   ],
   "source": [
    "# select top k predictors\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "k = 3\n",
    "selector = SelectKBest(f_classif, k)\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "idxs_selected = selector.get_support(indices=True) # get indices of columns to keep\n",
    "best_predictors = X.columns[idxs_selected]\n",
    "print('top {} predictors: {}'.format(k, best_predictors.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxP8FyIQfHdJQozwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b8fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117881a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYlzYzcwS8/8Ahsgg4+djWpIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11798ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visual inpsection\n",
    "for predictor in best_predictors:\n",
    "    for group in data.groupby('diagnosis'):\n",
    "        group[1][predictor].hist(label=group[0])\n",
    "        plt.title(predictor)\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inpsection confirms the results of our feature selection -- we can see that the distribution of values are indeed different between benign and malignant cells. This differentiation is what allows them to be useful predictors.\n",
    "\n",
    "For all three predictors -- concavity worst, concave points standard error and fractal dimenension mean -- malignant cells have a higher mean, median and modal value compared to benign cells. The variance also appears to be greater for malignant compared to benign cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Build a model to predict the malignant tumors.\n",
    "Use at least two classification techniques; compare and contrast the advantages and disadvantages of each.\n",
    "Identify how you would control for overfitting in each classification technique.\n",
    "Evaluate the performance of each model.\n",
    "In each model, identify the most important predictive variables and explain how you identified them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_error(y_true, y_hat):\n",
    "    accuracy = accuracy_score(y_true, y_hat)\n",
    "\n",
    "    scorecard = pd.DataFrame({'y_hat': y_hat, 'y_true': y_true})\n",
    "    false_positives = scorecard[(scorecard['y_true'] == 0) & (scorecard['y_hat'] == 1)]\n",
    "    false_negatives = scorecard[(scorecard['y_true'] == 1) & (scorecard['y_hat'] == 0)]\n",
    "    type_1_error = len(false_positives)/len(scorecard)\n",
    "    type_2_error = len(false_negatives)/len(scorecard)\n",
    "\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print('Type I error rate: {:.5f}'.format(type_1_error))\n",
    "    print('Type II error rate: {:.5f}'.format(type_2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.05%\n",
      "Type I error rate: 0.03509\n",
      "Type II error rate: 0.00439\n"
     ]
    }
   ],
   "source": [
    "# Technique 1: Logistic regression\n",
    "classifier = linear_model.LogisticRegression(penalty='l1', class_weight='balanced')\n",
    "probability_by_class = classifier.fit(x_train, y_train).predict_proba(x_test)\n",
    "y_hat = probability_by_class[:,0] < 0.68  # if probability of being in class M is greater than 0.68, classify as M.\n",
    "\n",
    "compute_classification_error(y_true=y_test, y_hat=y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.81%\n",
      "Type I error rate: 0.01754\n",
      "Type II error rate: 0.00439\n"
     ]
    }
   ],
   "source": [
    "# Technique 2: Gradient Boosted Trees\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_hat = model.predict(x_test)\n",
    "\n",
    "compute_classification_error(y_true=y_test, y_hat=y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.67%\n",
      "Type I error rate: 0.02193\n",
      "Type II error rate: 0.06140\n"
     ]
    }
   ],
   "source": [
    "# Technique 3: clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(x_train)\n",
    "y_hat = kmeans.predict(x_test)\n",
    "\n",
    "compute_classification_error(y_true=y_test, y_hat=y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>concave_points_mean</td>\n",
       "      <td>0.138743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>concave_points_worst</td>\n",
       "      <td>0.102094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smoothness_sd_error</td>\n",
       "      <td>0.083770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radius_sd_error</td>\n",
       "      <td>0.073298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.070681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Feature_importance\n",
       "21   concave_points_mean            0.138743\n",
       "23  concave_points_worst            0.102094\n",
       "13   smoothness_sd_error            0.083770\n",
       "1        radius_sd_error            0.073298\n",
       "24         symmetry_mean            0.070681"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance (for XGboost only)\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Feature_importance': model.feature_importances_})\n",
    "feature_importance.sort_values('Feature_importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "To Technical Audiences\n",
    "Explain the limitations of your analysis and identify possible further steps you could take.\n",
    "To Non-Technical Audiences\n",
    "Write a short summary of your analysis, explaining how your model works and how it performs.\n",
    "Briefly explain the factors that contributed to malignant vs benign tumor identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Audience**: I appled three classification techniques: logistic regression, gradient-boosted trees, and k-means clustering. All three are well-suited to classification problems, but are very different under the hood. Logistic regression is simply a regression model where the dependent variable is categorical; gradient-boosted trees is an ensemble decision tree with a well-defined objective function that includes both a loss function (e.g. MSE) and a regularization term to encourage parsimony and discourage over-fitting; k-means clustering iteratively assigns unlabeled data to one of K groups based on feature similarity.\n",
    "\n",
    "**Technical Audience**: All three techniques may be improved with a-priori information. In the case of logistic regression, it is useful to pre-select relevant features based on an ojbective criteria such as Akaike's Information Criterion (AIC), Bayesian Information Criterion (BIC) or Univariate Feature Selection. For gradient boosted trees, performance may be improved by hyperparameter tuning, such as selecting tree depth and the number of trees. In the case of k-means clustering, it is essential to have modeler intuition regarding the number of underlying groups that exist in the data, as given by k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Student Code Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**: Feel free to comment on style, library usage, or other improvements.  \n",
    "**Methodology**: Feel free to comment on the student's data setup, modeling methodology, and model evaluation.  \n",
    "** Conceptual Understanding**: Finally, feel free to add any suggestions or takeaways on how the student could continue to improve their understanding of these concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student sample 1\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import LinearRegression # from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "d = pd.read_csv('../data/train.csv') # Is the data available online? \n",
    "                                    # Is there any way to make the data accessible so others can repeat your analysis?\n",
    "# Setup data for prediction\n",
    "x1 = data.SalaryNormalized # Have you considered splitting your data into training/testing sets? \n",
    "                          # If you predict on the same data used to fit the model, you increase the chance of over-fitting \n",
    "                         # ... and your model may not perform well in a true predictive (e.g. out-of-sample) application.\n",
    "                        # Also, it is convention to represent the dependent variable with the variable Y and independent variables with X.\n",
    "x2 = pd.get_dummies(data.ContractType) # Is ContractType the only predictor? Are there other useful predictors  of SalaryNormalized?\n",
    "\n",
    "# Setup model\n",
    "model = LinearRegression() # Specify any underlying assumption explicity, e.g. are you fitting an intercept term? \n",
    "                          # Is the data normalized prior to fitting?\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.cross_validation import cross_val_score  # already imported above?\n",
    "from sklearn.cross_validation import train_test_split # import statements at the top of the document, please \n",
    "scores = cross_val_score(model, x2, x1, cv=1, scoring='mean_absolute_error') # cv=1 implies 1-fold in the cross-validation. \n",
    "                                                                            # Is that enough? How about 10?\n",
    "print(scores.mean())\n",
    "\n",
    "# Please add an interpretation of your results. \n",
    "# How good is the model? \n",
    "# Does it have predictive skill out-of-sample? \n",
    "# What can you ascertain about the underlying relationship between your independent and dependent variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student sample 2\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../data/train.csv') # Is the data open-source? How can others access it to reproduce your results?\n",
    "\n",
    "# Setup data for prediction\n",
    "y = data.SalaryNormalized\n",
    "X = pd.get_dummies(data.ContractType) # Train/Test sets? \n",
    "                                    # How do you plan to evaluate the predictive power of your model besides cross-validation?\n",
    "\n",
    "# Setup model\n",
    "model = LinearRegression() # Are there any underlying assumptions here? Please specify.\n",
    "                          # For example, do you expect a linear relationship between Salary and ContractType?\n",
    "                         # Are assumption of IID satisfied?\n",
    "                        # Can you include model diagnostic plots? \n",
    "                       # e.g. visually-inspect for normality of model residuals, heteroscadasticity, autocorrelation, etc...\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error') # nice use of keyword argument specification!\n",
    "print(scores.mean()) # can you contextualize these results? Is this good? Bad? Ugly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
